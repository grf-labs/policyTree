---
title: "policytree introduction"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{policytree introduction}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

This document provides a short introduction to the `policytree` package, with examples from Zhou, Athey and Wager (2018), and Athey and Wager (2017). The last section addresses details, such as treatment estimates with one-vs-all grf, and the runtime of `policy_tree`.

```{r, echo = FALSE, message = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
set.seed(42)
```

```{r setup}
library(policytree)
library(grf)
```

# Ex. 1: Binary treatment effect estimation and policy learning
```{r}
n <- 10000
p <- 10

X <- matrix(rnorm(n * p), n, p)
ee <- 1 / (1 + exp(X[, 3]))
tt <- 1 / (1 + exp((X[, 1] + X[, 2]) / 2)) - 0.5
W <- rbinom(n, 1, ee)
Y <- X[, 3] + W * tt + rnorm(n)

cf <- causal_forest(X, Y, W)

plot(tt, predict(cf)$predictions)

dr <- double_robust_scores(cf)
tree <- policy_tree(X, dr, 2)
tree
pp <- predict(tree, X)
boxplot(tt ~ pp)
plot(tree)

plot(X[, 1], X[, 2], col = pp)
abline(0, -1, lwd = 4, col = 4)
```

# Ex. 2: Multi-action treatment effect estimation

The following example is from the 3-action DGP from section 6.4.1 in [Zhou, Athey and Wager (2018)](https://arxiv.org/abs/1810.04778)

```{r}
n <- 10000
p <- 10
data <- gen_data_mapl(n, p)
head(data.frame(data)[1:6])

X <- data$X
Y <- data$Y
W <- data$action

multi.forest <- multi_causal_forest(X, Y, W)

# tau.hats:
head(predict(multi.forest)$predictions)

# Each region with optimal action
region.pp <- data$region + 1
plot(X[, 5], X[, 7], col = region.pp)
leg <- sort(unique(region.pp))
legend("topleft", legend = leg - 1, col = leg, pch = 10)
```

### Policy learning

Cross-fitted Augmented Inverse Propensity Weighted Learning (CAIPWL) with the optimal depth 2 tree

```{r}
Gamma.matrix <- double_robust_scores(multi.forest)
head(Gamma.matrix)

train <- sample(1:n, 9000)
opt.tree <- policy_tree(X[train, ], Gamma.matrix[train, ], depth = 2)
opt.tree

plot(opt.tree)
```

Predict treatment on held out data

```{r}
X.test <- X[-train, ]
pp <- predict(opt.tree, X.test)
head(pp)

plot(X.test[, 5], X.test[, 7], col = pp)
leg <- sort(unique(pp))
legend("topleft", legend = leg - 1, col = leg, pch = 10)
```

# Ex. 3: Efficient Policy Learning - Binary Treatment and Instrumental Variables

The following example is from section 5.2 in [Wager and Athey (2017)](https://arxiv.org/abs/1702.02896).

```{r}
n <- 500
data <- gen_data_epl(n, type = "continuous")
head(data.frame(data))[1:6]

iv.forest <- instrumental_forest(X = data$X, Y = data$Y, W = data$W, Z = data$Z)

gamma <- double_robust_scores(iv.forest)
head(gamma)
```

Find the depth-2 tree which solves (2):

```{r}
train <- sample(1:400)
tree <- policy_tree(data$X[train, ], gamma[train, ])
tree
```

Evaluate the policy on held out data:

```{r}
piX <- predict(tree, data$X[-train, ]) - 1
head(piX)

reward.policy <- mean((2 * piX - 1) * data$tau[-train])
reward.policy
```

# Multi causal forest treatment estimates and baselines

This is a worked example of how `multi_causal_forest` treatment estimates can be decomposed (and interpreted) to target the parameter you are interested in. Consider the following DGP:


```{r}
n <- 10000
p <- 5
X <- matrix(rnorm(n * p), n, p)
W <- sample(c("A", "B", "C"), n, replace = TRUE)
tauB <- X[, 2]
tauC <- 2 * X[, 2]
Y <- X[, 1] + tauB * (W == "B") + tauC * (W == "C") + rnorm(n)
mcf <- multi_causal_forest(X, Y, W)
tau.mcf <- predict(mcf)$predictions
```

Recall that `multi_causal_forest` simply fits one `causal_forest` per treament, with the same nuisance component $Y.hat = m(x) = E[Y | X]$ for each forest. Each forest returns a treatment estimate  $\tau_k(x) = \frac{\mu_k(x) - m(x)}{1 - e_k(x)}$, where $\mu_k(x) = E[Y | X, W=W_k]$ is the conditional mean of arm $k$ and $e_k(x)$ is the assignment probability of arm $k$.

In the above DGP

$m(x) = X1 + 1/3 X2 + 1/3 \cdot 2X2 = X1 + X2$

$\mu_B = X1 + X2$

$\mu_C = X1 + 2X2$

$e_B(x) = e_C(x) = 1/3$

Which gives the multi causal forest predictions:

$\tau_B(X) = (X1 + X2 - (X1 + X2)) / (1 - 1/3) = 0$

$\tau_C(X) = (X1 + X2 - (X1 + 2X2)) / (1 - 1/3) = 3/2 X2$

I.e, the estimated $\tau_B(x)$ will be zero because of the centering step. The estimate for $\tau_C(X)$ should be scaled by $4/3$ in order to be compared with ground truth ($2 X2)$:

```{r}
plot(X[, 2], tauB, type = "l", lwd = 1)
points(X[, 2], tau.mcf[, "B"], col = 2, cex = 0.1)
lines(X[, 2], tauC, lwd = 3)
points(X[, 2], tau.mcf[, "C"], col = 3, cex = 0.1)
points(X[, 2], 4/3 * tau.mcf[, "C"], col = 4, cex = 0.1)
legend = c("treatment B", "tau.mcf[,'B']",
           "treatment C", "tau.mcf[,'C']", "4/3 tau.mcf[,'C'] ")
legend("topleft", legend = legend,
       col = c(1, 2, 1, 3, 4),
       pch = c(NA, 19, NA, 19, 19),
       bg = "transparent",
       bty = "n",
       lwd = c(1, NA, 3, NA, NA))
```

Naturally the following regression coefficient is close to $4/3$
```{r}
lm(tauC ~ tau.mcf[, "C"] - 1)
```

# Gauging the runtime of tree search

The amortized runtime of the exact tree search is $O(p^k n^k (log n + d) + pnlog n)$ where $p$ is the number of features, $d$ the number of treatments, $n$ the number of observations, and $k \geq 1$ the tree depth.

For a depth two tree this is $O(p^2 n^2 (log n + d))$ (ignoring the last term which is a global sort done at the beginning) meaning that it scales quadratically with the number of observations, i.e. if you double the number of observations, the search will take at least four times as long.

For a depth three tree it is $O(p^3 n^3 (log n + d))$. If a depth two tree with 1000 observations, 4 features and 3 actions took around t seconds, you can expect the level three tree to take approximately $1000\cdot 4$ times as long ($\approx\frac{p^3n^2}{p^2n^2}=pn$)

The runtime above is with continuous features. There are considerable time savings when the features are
discrete. In the extreme case with all binary observations, the runtime will be practically linear in n.

The optional approximation parameter `split.step` emulates rounding the data and is recommended to experiment with in order to reduce the runtime.
