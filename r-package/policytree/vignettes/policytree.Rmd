---
title: "policytree introduction"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{policytree introduction}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

This document provides a short introduction to the `policytree` package, with examples from Zhou, Athey and Wager (2018), and Athey and Wager (2021). The last section contains details on the runtime of `policy_tree`.

```{r, echo = FALSE, message = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
set.seed(42)
```

```{r setup}
library(policytree)
library(grf)
```

# Ex. 1: Binary treatment effect estimation and policy learning
```{r}
n <- 10000
p <- 10

X <- matrix(rnorm(n * p), n, p)
ee <- 1 / (1 + exp(X[, 3]))
tt <- 1 / (1 + exp((X[, 1] + X[, 2]) / 2)) - 0.5
W <- rbinom(n, 1, ee)
Y <- X[, 3] + W * tt + rnorm(n)

cf <- causal_forest(X, Y, W)

plot(tt, predict(cf)$predictions)

dr <- double_robust_scores(cf)
tree <- policy_tree(X, dr, 2)
tree
pp <- predict(tree, X)
boxplot(tt ~ pp)
plot(tree)

plot(X[, 1], X[, 2], col = pp)
abline(0, -1, lwd = 4, col = 4)
```

# Ex. 2: Multi-action treatment effect estimation

The following example is from the 3-action DGP from section 6.4.1 in [Zhou, Athey and Wager (2018)](https://arxiv.org/abs/1810.04778)

```{r}
n <- 10000
p <- 10
data <- gen_data_mapl(n, p)
head(data.frame(data)[1:6])

X <- data$X
Y <- data$Y
W <- data$action

multi.forest <- multi_arm_causal_forest(X, Y, W)

# tau.hats:
head(predict(multi.forest)$predictions[,,])

# Each region with optimal action
region.pp <- data$region + 1
plot(X[, 5], X[, 7], col = region.pp)
leg <- sort(unique(region.pp))
legend("topleft", legend = leg - 1, col = leg, pch = 10)
```

### Policy learning

Cross-fitted Augmented Inverse Propensity Weighted Learning (CAIPWL) with the optimal depth 2 tree

```{r}
Gamma.matrix <- double_robust_scores(multi.forest)
head(Gamma.matrix)

train <- sample(1:n, 9000)
opt.tree <- policy_tree(X[train, ], Gamma.matrix[train, ], depth = 2)
opt.tree

plot(opt.tree)
```

Predict treatment on held out data

```{r}
X.test <- X[-train, ]
pp <- predict(opt.tree, X.test)
head(pp)

plot(X.test[, 5], X.test[, 7], col = pp)
leg <- sort(unique(pp))
legend("topleft", legend = leg - 1, col = leg, pch = 10)
```

# Ex. 3: Efficient Policy Learning - Binary Treatment and Instrumental Variables

The following example is from section 5.2 in [Wager and Athey (2021)](https://arxiv.org/abs/1702.02896).

```{r}
n <- 500
data <- gen_data_epl(n, type = "continuous")
head(data.frame(data))[1:6]

iv.forest <- instrumental_forest(X = data$X, Y = data$Y, W = data$W, Z = data$Z)

gamma <- double_robust_scores(iv.forest)
head(gamma)
```

Find the depth-2 tree which solves (2):

```{r}
train <- sample(1:400)
tree <- policy_tree(data$X[train, ], gamma[train, ])
tree
```

Evaluate the policy on held out data:

```{r}
piX <- predict(tree, data$X[-train, ]) - 1
head(piX)

reward.policy <- mean((2 * piX - 1) * data$tau[-train])
reward.policy
```

# Gauging the runtime of tree search

Exact tree search is intended as a way to find shallow (i.e. depth 2 or 3) globally optimal tree-based polices on datasets of "moderate" size. The amortized runtime of the exact tree search is $O(p^k n^k (log n + d) + pnlog n)$ where $p$ is the number of features, $n$ the number of observations, $d$ the number of treatments, and $k \geq 1$ the tree depth. Due to the exponents in this expression, exact tree search will not scale to datasets of arbitrary size.

As an example, the runtime of a depth two tree scales quadratically with the number of observations, implying that doubling the number of samples will quadruple the runtime. n refers to the number of distinct observations, substantial speedups can be grained when the features are discrete (with all binary features, the runtime will be ~ linear in n), and it is often beneficial to round down very dense data to a lower cardinality (the optional parameter split.step emulates this, though rounding/re-encoding allow for finer-grained control).

As a point of reference, the following table presents runtimes for some example problems.

| depth | n (continuous) | features | actions | split.step | time    |
|-------|----------------|----------|---------|------------|---------|
| 2     | 1000           | 30       | 20      | 1          | 1.5 min |
| 2     | 1000           | 30       | 20      | 10         | 7 sec   |
| 2     | 10 000         | 30       | 20      | 1          | 3 hrs   |
| 2     | 10 000         | 30       | 20      | 10         | 14 min  |
| 2     | 10 000         | 30       | 20      | 1, but `round(X, 2)`         | 8 min   |
| 2     | 100 000        | 30       | 20      | 10         | 50 hrs |
| 2     | 100 000        | 30       | 20      | 1, but `round(X, 2)`         | 6.3 hrs |
| 2     | 100 000        | 60       | 20      | 1, but `round(X, 2)`         | 25 hrs |
| 2     | 100 000        | 30       | 3       | 10         | 7.4 hrs |
